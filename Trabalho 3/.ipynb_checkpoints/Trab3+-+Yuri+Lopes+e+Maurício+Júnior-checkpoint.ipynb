{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<header style=\"text-align: center;\">\n",
    "    <h1 style=\"font-variant: small-caps; padding-bottom: .5em;\">\n",
    "        Trabalho 3 - Yuri Lopes e Maurício Júnior\n",
    "    </h1>\n",
    "</header>\n",
    "<!-- Endliche Differenzmethode -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Fonte: http://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html\n",
    "\n",
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets and performance metrics\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "class Report:\n",
    "    \n",
    "    @staticmethod\n",
    "    def run(classifier):\n",
    "        # We learn the digits on the first half of the digits\n",
    "        classifier.fit(data[:n_samples // 2], digits.target[:n_samples // 2])\n",
    "\n",
    "        # Now predict the value of the digit on the second half:\n",
    "        expected = digits.target[n_samples // 2:]\n",
    "        predicted = classifier.predict(data[n_samples // 2:])\n",
    "\n",
    "        accuracy = accuracy_score(predicted, expected)\n",
    "\n",
    "        print(\"SVM\\n\")\n",
    "        print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "        print(\"\\nAccuracy: %s\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "\n",
      "Confusion matrix:\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 88  1  0  0  0  0  0  1  1]\n",
      " [ 0  0 85  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 79  0  3  0  4  5  0]\n",
      " [ 0  0  0  0 88  0  0  0  0  4]\n",
      " [ 0  0  0  0  0 88  1  0  0  2]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 88  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 88  0]\n",
      " [ 0  0  0  1  0  1  0  0  0 90]]\n",
      "\n",
      "Accuracy: 0.968854282536\n"
     ]
    }
   ],
   "source": [
    "# Import classifier\n",
    "from sklearn import svm\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(gamma=0.001)\n",
    "\n",
    "Report.run(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "\n",
      "Confusion matrix:\n",
      "[[86  0  0  0  1  0  1  0  0  0]\n",
      " [ 1 79  0  3  1  2  1  0  0  4]\n",
      " [ 0  0 86  0  0  0  0  0  0  0]\n",
      " [ 0  0  2 77  0  3  0  0  6  3]\n",
      " [ 2  0  0  0 85  0  1  1  0  3]\n",
      " [ 0  0  0  0  0 87  1  0  0  3]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  1  0  3  3  0 78  0  4]\n",
      " [ 0  3  0  1  1  3  0  1 76  3]\n",
      " [ 1  0  0  2  0  2  0  0  0 87]]\n",
      "\n",
      "Accuracy: 0.924360400445\n"
     ]
    }
   ],
   "source": [
    "# Import classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "classifier = MLPClassifier(solver='lbfgs', alpha=1e-5)\n",
    "\n",
    "Report.run(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "\n",
      "Confusion matrix:\n",
      "[[86  0  0  0  1  0  0  0  1  0]\n",
      " [ 0 60  8  0  2  1  0  0  9 11]\n",
      " [ 1  3 75  5  0  0  0  0  0  2]\n",
      " [ 0  0  1 76  0  2  0  4  6  2]\n",
      " [ 1  0  0  0 86  0  0  2  3  0]\n",
      " [ 0  0  0  0  1 64  2  0  0 24]\n",
      " [ 0  2  0  0  0  0 89  0  0  0]\n",
      " [ 0  0  2  0  4  2  0 80  1  0]\n",
      " [ 0  2  2  0  1  4  0  1 73  5]\n",
      " [ 0  0  0  3  0  3  0  3  2 81]]\n",
      "\n",
      "Accuracy: 0.856507230256\n"
     ]
    }
   ],
   "source": [
    "# Import classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "Report.run(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Discussão dos Resultados\n",
    "O classificador SVM apresentou melhores resultados em acurácia que os outros dois outros classificadores.\n",
    "\n",
    "O classificador de redes neurais obteve resultado competitivo com SVM e, provavelmente ajustando parâmetros dos dois classificadores poder-se-ia obter resultados ainda melhores. O mesmo vale para o Nayve Bayes em termos de obter melhores resultados, embora sua acurácia não tenha sido competitiva em relação aos outros dois.\n",
    "\n",
    "Em particular, o Nayve Bayes obteve o pior resultado, mas é importante lembrar que esse método é mais rápido, fácil de treinar e interpretar os resultados que redes neurais e SVM. Adaptar o Nayve Bayes de maneira incremental ou para novos dados é simples e rápido, já fazer isso para redes neurais pode não trazer bons resultados e talvez exigir mudanças na topologia da rede.\n",
    "Em relação ao SVM, o Nayve Bayes assume independência entre as features, já o SVM, em termos simples, olha a interação entre essas features até um certo grau. Apesar disso, o consumo de memória e tempo de execução do SVM pode crescer muito em relação ao Nayve Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
