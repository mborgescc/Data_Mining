{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<header style=\"text-align: center;\">\n",
    "    <h1 style=\"font-variant: small-caps; padding-bottom: .5em;\">\n",
    "        Trabalho 3 - Yuri Lopes e Maurício Júnior\n",
    "    </h1>\n",
    "</header>\n",
    "<!-- Endliche Differenzmethode -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "\n",
      "Confusion matrix:\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 88  1  0  0  0  0  0  1  1]\n",
      " [ 0  0 85  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 79  0  3  0  4  5  0]\n",
      " [ 0  0  0  0 88  0  0  0  0  4]\n",
      " [ 0  0  0  0  0 88  1  0  0  2]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 88  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 88  0]\n",
      " [ 0  0  0  1  0  1  0  0  0 90]]\n",
      "\n",
      "Accuracy: 0.968854282536\n"
     ]
    }
   ],
   "source": [
    "# Fonte: http://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html\n",
    "\n",
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(gamma=0.001)\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(data[:n_samples // 2], digits.target[:n_samples // 2])\n",
    "\n",
    "# Now predict the value of the digit on the second half:\n",
    "expected = digits.target[n_samples // 2:]\n",
    "predicted = classifier.predict(data[n_samples // 2:])\n",
    "\n",
    "accuracy = accuracy_score(predicted, expected)\n",
    "\n",
    "print(\"SVM\\n\")\n",
    "\n",
    "#print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    " #     % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "\n",
    "print(\"\\nAccuracy: %s\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network\n",
      "\n",
      "Confusion matrix:\n",
      "[[86  0  0  0  0  0  2  0  0  0]\n",
      " [ 0 84  0  1  0  0  0  0  0  6]\n",
      " [ 0  0 86  0  0  0  0  0  0  0]\n",
      " [ 0  0  3 79  0  4  0  0  5  0]\n",
      " [ 1  1  0  0 84  0  3  0  0  3]\n",
      " [ 0  0  1  1  0 84  2  0  0  3]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  2  0  0  0  0 84  0  3]\n",
      " [ 0  4  0  0  0  3  1  0 80  0]\n",
      " [ 2  0  0  1  0  2  0  3  0 84]]\n",
      "\n",
      "Accuracy: 0.935483870968\n"
     ]
    }
   ],
   "source": [
    "# Fonte: http://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html\n",
    "\n",
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "classifier = MLPClassifier(solver='lbfgs', alpha=1e-5)\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(data[:n_samples // 2], digits.target[:n_samples // 2])\n",
    "\n",
    "# Now predict the value of the digit on the second half:\n",
    "expected = digits.target[n_samples // 2:]\n",
    "predicted = classifier.predict(data[n_samples // 2:])\n",
    "\n",
    "accuracy = accuracy_score(predicted, expected)\n",
    "\n",
    "print(\"Neural Network\\n\")\n",
    "\n",
    "#print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    " #     % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "\n",
    "print(\"\\nAccuracy: %s\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "\n",
      "Confusion matrix:\n",
      "[[86  0  0  0  1  0  0  0  1  0]\n",
      " [ 0 60  8  0  2  1  0  0  9 11]\n",
      " [ 1  3 75  5  0  0  0  0  0  2]\n",
      " [ 0  0  1 76  0  2  0  4  6  2]\n",
      " [ 1  0  0  0 86  0  0  2  3  0]\n",
      " [ 0  0  0  0  1 64  2  0  0 24]\n",
      " [ 0  2  0  0  0  0 89  0  0  0]\n",
      " [ 0  0  2  0  4  2  0 80  1  0]\n",
      " [ 0  2  2  0  1  4  0  1 73  5]\n",
      " [ 0  0  0  3  0  3  0  3  2 81]]\n",
      "\n",
      "Accuracy: 0.856507230256\n"
     ]
    }
   ],
   "source": [
    "# Fonte: http://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html\n",
    "\n",
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(data[:n_samples // 2], digits.target[:n_samples // 2])\n",
    "\n",
    "# Now predict the value of the digit on the second half:\n",
    "expected = digits.target[n_samples // 2:]\n",
    "predicted = classifier.predict(data[n_samples // 2:])\n",
    "\n",
    "accuracy = accuracy_score(predicted, expected)\n",
    "\n",
    "print(\"Naive Bayes\\n\")\n",
    "\n",
    "#print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    " #     % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "\n",
    "print(\"\\nAccuracy: %s\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussão dos Resultados\n",
    "O classificador SVM apresentou melhores resultados em acurácia que os outros dois outros classificadores.\n",
    "\n",
    "O classificador de redes neurais obteve resultado competitivo com SVM e, provavelmente ajustando parâmetros dos dois classificadores poder-se-ia obter resultados ainda melhores. O mesmo vale para o Nayve Bayes em termos de obter melhores resultados, embora sua acurárcia não tenha sido competitiva em relação aos outros dois.\n",
    "\n",
    "Em particular, o Nayve Bayes obteve o pior resultado, mas é importante lembrar que esse método é mais rápido, fácil de treinar e interpretar os resultados que redes neurais e SVM. Adaptar o Nayve Bayes de maneira incremental ou para novos dados é simples e rápido, já fazer isso para redes neurais pode não trazer bons resultados e talvez exigir mudanças na topologia da rede.\n",
    "Em relação ao SVM, o Nayve Bayes assume independência entre as features, já o SVM, em termos simples, olha a interação entre essas features até um certo grau. Apesar disso, o consumo de memória e tempo de execução do SVM pode crescer muito em relação ao Nayve Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
